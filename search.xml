<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Running Node.js on Linux with systemd]]></title>
    <url>%2F2018%2F06%2F14%2FRunning-Node-js-on-Linux-with-systemd%2F</url>
    <content type="text"><![CDATA[今天在思考如何在Linux服务器上不依赖PM2部署直接部署Python Web服务时，碰巧搜到的这片文章。作为一片入门教程，作者给出了非常明确的思路和操作示例，并在字里行间和文末明列出了推荐阅读材料。为推荐给各位阅读，这里我做了全文的复制，原文链接。 感谢作者Luke Bond，有机会我会将全文翻译成中文。 The Node.js community has embraced process monitoring tools such as PM2, Nodemon, and Forever, which is understandable. For example, in addition to process monitoring, PM2 also boasts features around logging and port-sharing or clustering. However, I’m a firm believer in using the Linux init system for process monitoring. In this blog post, I’ll show you how to recreate process management, logging and clustering functionality using the Linux init system, systemd, and I’ll make the case for this being a superior approach. Please note that I’ve no intention of casting aspersions on any of the tools I’ve mentioned. But I think gaining familiarity with Linux is important for Node.js developers; it’s important to use standard tools that are well-proven and widely understood by sysadmins everywhere. A Note about PM2I will be making reference to PM2 because it has become ubiquitous in the Node.js community, and therefore it will serve as most people’s frame of reference. PM2 makes it very easy to do: Process management Log management Port-sharing magic for Node.js applications PM2’s ease of use is certainly one of its strongest points; it hides some of the operational realities of running services on Linux from Node.js developers. In this blog post, I’m going to show you how to do each of these three things with systemd. An Explanation of Linux Init SystemsAlthough PM2 and similar tools are ubiquitous in the Node.js world, that’s not necessarily the case in other communities. Running your application with the Linux init system will ensure that it’s familiar to any Linux sysadmin. Therefore, knowing more about Linux, the operating system on which the vast majority of Node.js applications run, is very important for Node.js developers. First, let’s run through a brief primer on what Linux init systems are. Each Linux distribution has a master process running as PID 1 (process ID 1) that is the ancestor of all processes that run on the system. Even if an application spawns a bunch of child processes and orphans them, the init system will still be their ancestor and will clean them up. The init system is responsible for starting and stopping services on boot. Typically, sysadmins will write init scripts to start, stop, and restart each service (e.g., databases, web servers). Basically, the Linux init system is the ultimate process monitor. systemd is more or less the standard Linux system in the latest release of most Linux distributions, so that’s the one I’m going to cover here. It should be relatively easy to translate these concepts into another init system, such as upstart. Creating a Sample Node.js ApplicationTo aid explanation, I’m going to use a simple, contrived Node.js application that talks to Redis. It has one HTTP endpoint that outputs “Hello, World!” and a counter taken from Redis. It can be found here: https://github.com/lukebond/demo-api-redis You will also need: A Linux distribution running systemd Node.js installed Redis installed (but not running) Clone the above repository to somewhere in your Linux system and run npm install. Creating Unit FilesNext we’ll create a unit file for our Node.js service. A unit file is what systemd uses to describe a service, its configuration, how to run it, and so on. It’s a text file similar to an INI file. Create the following text file and copy it to /etc/systemd/system/demo-api-redis@.service: 123456789101112[Unit]Description=HTTP Hello WorldAfter=network.target[Service]User=lukeEnvironment=REDIS_HOST=localhostWorkingDirectory=/home/luke/Development/demo-api-redisExecStart=/usr/bin/node index.js[Install]WantedBy=multi-user.target Remember! Modify the path on the WorkingDirectory= line to the location where you cloned the git repository. Now that the unit file is created and is in the correct location on your system, we need to tell systemd to reload its config to pick up the new unit file, then enable and start the service: 123$ systemctl daemon-reload$ systemctl enable demo-api-redis@1$ systemctl start demo-api-redis@1 Learn more about how to use systemctl here. Enabling a service means that systemd will start that service automatically on boot, but it doesn’t start it now. Starting a service is required to start the service now. Check the status of the service to see if it worked: 12345678910$ systemctl status demo-api-redis@1● demo-api-redis@1.service - HTTP Hello World Loaded: loaded (/etc/systemd/system/demo-api-redis@.service; enabled; vendor preset: disabled) Active: activating (auto-restart) (Result: exit-code) since Thu 2016-06-30 17:20:09 BST; 62ms ago Process: 29787 ExecStart=/usr/bin/node index.js (code=exited, status=1/FAILURE) Main PID: 29787 (code=exited, status=1/FAILURE)Jun 30 17:20:09 luke-arch systemd[1]: demo-api-redis@1.service: Main process exited, code=exited, status=1/FAILUREJun 30 17:20:09 luke-arch systemd[1]: demo-api-redis@1.service: Unit entered failed state.Jun 30 17:20:09 luke-arch systemd[1]: demo-api-redis@1.service: Failed with result 'exit-code'. This is failing because Redis isn’t running. Let’s explore dependencies in systemd! Exploring systemd DependenciesWe can add the Wants= directive to the [Unit] section of a unit file to declare dependencies between services. There are other directives with different semantics (e.g., Requires=) but Wants= will cause the depended-upon service (in this case, Redis) to be started when our Node.js service is started. Your unit file should now look like this: 12345678910111213[Unit]Description=HTTP Hello WorldAfter=network.targetWants=redis.service[Service]User=lukeEnvironment=REDIS_HOST=localhostWorkingDirectory=/home/luke/Development/demo-api-redisExecStart=/usr/bin/node index.js[Install]WantedBy=multi-user.target Signal systemd to reload its config: 1$ systemctl daemon-reload Ask systemd to cat the unit file just to ensure it has picked up our changes: 123456789101112131415$ systemctl cat demo-api-redis@1# /etc/systemd/system/demo-api-redis@.service[Unit]Description=HTTP Hello WorldAfter=network.targetWants=redis.service[Service]Environment=REDIS_HOST=localhostUser=lukeWorkingDirectory=/home/luke/Development/demo-api-redisExecStart=/usr/bin/node index.js[Install]WantedBy=multi-user.target And now restart the service. We can see that the service now works: 12345678910111213$ systemctl restart demo-api-redis@1$ systemctl status demo-api-redis@1● demo-api-redis@1.service - HTTP Hello World Loaded: loaded (/etc/systemd/system/demo-api-redis@.service; enabled; vendor preset: disabled) Active: active (running) since Thu 2016-06-30 17:17:19 BST; 187ms ago Main PID: 27050 (node) Tasks: 10 (limit: 512) CGroup: /system.slice/system-demo\x2dapi\x2dredis.slice/demo-api-redis@1.service └─27050 /usr/bin/node index.jsJun 30 17:17:19 luke-arch systemd[1]: Started HTTP Hello World.$ curl localhost:9000"Hello, world 192.168.1.39! 1 hits." It works because it has triggered Redis to run: 123456789101112131415161718192021$ systemctl status redis● redis.service - Advanced key-value store Loaded: loaded (/usr/lib/systemd/system/redis.service; disabled; vendor preset: disabled) Active: active (running) since Fri 2016-07-01 10:31:54 BST; 3s ago Main PID: 28643 (redis-server) Tasks: 3 (limit: 512) Memory: 6.3M CPU: 10ms CGroup: /system.slice/redis.service └─28643 /usr/bin/redis-server 127.0.0.1:6379 Jul 01 10:31:54 luke-arch redis-server[28643]: `-._ `-._`-.__.-'_.-' _.-'Jul 01 10:31:54 luke-arch redis-server[28643]: `-._ `-.__.-' _.-'Jul 01 10:31:54 luke-arch redis-server[28643]: `-._ _.-'Jul 01 10:31:54 luke-arch redis-server[28643]: `-.__.-'Jul 01 10:31:54 luke-arch redis-server[28643]: 28643:M 01 Jul 10:31:54.216 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.Jul 01 10:31:54 luke-arch redis-server[28643]: 28643:M 01 Jul 10:31:54.216 # Server started, Redis version 3.2.1Jul 01 10:31:54 luke-arch redis-server[28643]: 28643:M 01 Jul 10:31:54.216 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memoryJul 01 10:31:54 luke-arch redis-server[28643]: 28643:M 01 Jul 10:31:54.216 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with RedJul 01 10:31:54 luke-arch redis-server[28643]: 28643:M 01 Jul 10:31:54.216 * DB loaded from disk: 0.000 secondsJul 01 10:31:54 luke-arch redis-server[28643]: 28643:M 01 Jul 10:31:54.216 * The server is now ready to accept connections on port 6379 Process ManagementThe first item of PM2 functionality we’re working toward is process management. This means restarting services when they crash and when the machine reboots. Do we have this functionality yet? Let’s find out. 12345678910111213141516$ systemctl status demo-api-redis@1 | grep "PID" Main PID: 28649 (node)$ sudo kill -9 28649$ systemctl status demo-api-redis@1● demo-api-redis@1.service - HTTP Hello World Loaded: loaded (/etc/systemd/system/demo-api-redis@.service; enabled; vendor preset: disabled) Active: failed (Result: signal) since Fri 2016-07-01 10:55:49 BST; 2s ago Process: 29145 ExecStart=/usr/bin/node index.js (code=killed, signal=KILL) Main PID: 29145 (code=killed, signal=KILL)Jul 01 10:55:39 luke-arch systemd[1]: Started HTTP Hello World.Jul 01 10:55:40 luke-arch node[29145]: (node:29145) DeprecationWarning: process.EventEmitter is deprecated. Use require('events') instead.Jul 01 10:55:40 luke-arch node[29145]: Listening on port 9000Jul 01 10:55:49 luke-arch systemd[1]: demo-api-redis@1.service: Main process exited, code=killed, status=9/KILLJul 01 10:55:49 luke-arch systemd[1]: demo-api-redis@1.service: Unit entered failed state.Jul 01 10:55:49 luke-arch systemd[1]: demo-api-redis@1.service: Failed with result 'signal'. So systemd is not restarting our service when it crashes, but never fear — systemd has a range of options for configuring this behavior. Adding the following to the [Service] section of our unit file will be fine for our purposes: 123Restart=alwaysRestartSec=500msStartLimitInterval=0 This tells systemd to always restart the service after a 500ms delay. You can configure it to give up eventually, but this should be fine for our purposes. Now reload systemd’s config and restart the service and try killing the process: 123456789101112131415161718192021222324252627282930313233$ systemctl daemon-reload$ systemctl cat demo-api-redis@1# /etc/systemd/system/demo-api-redis@.service[Unit]Description=HTTP Hello WorldAfter=network.targetWants=redis.service[Service]Environment=REDIS_HOST=localhostUser=lukeWorkingDirectory=/home/luke/Development/demo-api-redisExecStart=/usr/bin/node index.js[Install]WantedBy=multi-user.target$ systemctl restart demo-api-redis@1$ systemctl status demo-api-redis@1.service | grep PID Main PID: 29145 (code=killed, signal=KILL)$ sudo kill -9 29145$ systemctl status demo-api-redis@1● demo-api-redis@1.service - HTTP Hello World Loaded: loaded (/etc/systemd/system/demo-api-redis@.service; disabled; vendor preset: disabled) Active: active (running) since Fri 2016-07-01 11:08:41 BST; 2s ago Main PID: 29884 (node) Tasks: 10 (limit: 512) CGroup: /system.slice/system-demo\x2dapi\x2dredis.slice/demo-api-redis@1.service └─29884 /usr/bin/node index.jsJul 01 11:08:41 luke-arch systemd[1]: Stopped HTTP Hello World.Jul 01 11:08:41 luke-arch systemd[1]: Started HTTP Hello World.Jul 01 11:08:41 luke-arch node[29884]: (node:29884) DeprecationWarning: process.EventEmitter is deprecated. Use require('events') instead.Jul 01 11:08:41 luke-arch node[29884]: Listening on port 9000 It works! systemd is now restarting our service when it goes down. It will also start it up automatically if the machine reboots (that’s what it means to enable a service). Go ahead and reboot to prove it. We’ve now recreated one of our three PM2 features: process management. Let’s move on to the next one. LoggingThis is the easiest of our three target features. systemd has a very powerful logging tool called journalctl. It’s a sysadmin’s Swiss Army knife of logging, and it can do anything you’ll ever need from a logging tool. No Node.js userland tool comes close. To scroll through logs for a unit or service: 1$ journalctl -u demo-api-redis@1 To follow the same: 1$ journalctl -u demo-api-redis@1 -f You can ask for logs since the last boot: 1$ journalctl -u demo-api-redis@1 --boot Or since a specific time, in various ways: 1234$ journalctl -u demo-api-redis@1 --since 08:00$ journalctl -u demo-api-redis@1 --since today$ journalctl -u demo-api-redis@1 --since yesterday$ journalctl -u demo-api-redis@1 --since 2016-06-02 15:36:00 You can filter by log level (console.log, console.error, etc.): 1$ journalctl -u demo-api-redis@1 -p err There is so much more you can do; it’s super powerful. This article is a great place to start to learn all about journalctl. Multiple InstancesWe’ve covered two of our three features now. The last one is port sharing, or clustering as it is often called in the Node.js world. But before we can address that, we need to be able to run multiple instances of our service. You may have noticed that our unit file has an @ symbol in the filename, and that we’ve been referring to our service as demo-api-redis@1. The 1 after the @ symbol is the instance name (it doesn’t have to be a number). We could run two more instances of our service using something like systemctl start demo-api-redis@{2,3}, but first we need them to bind to different ports or they’ll clash. Our sample app takes an environment variable to set the port, so we can use the instance name to give each service a unique port. Add the following additional Environment= line to the [Service] section of the unit file: 1Environment=LISTEN_PORT=900%i This will mean that demo-api-redis@1 will get port 9001, demo-api-redis@2 will get port 9002, and demo-api-redis@3 will get port 9003, leaving 9000 for our load balancer. Once you’ve edited the unit file, you need to reload the config, check that it’s correct, start two new instances, and restart the existing one: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657$ systemctl daemon-reload$ systemctl cat demo-api-redis@1# /etc/systemd/system/demo-api-redis@.service[Unit]Description=HTTP Hello WorldAfter=network.targetWants=redis.service[Service]Environment=REDIS_HOST=localhostEnvironment=LISTEN_PORT=900%iUser=lukeWorkingDirectory=/home/luke/Development/demo-api-redisExecStart=/usr/bin/node index.jsRestart=alwaysRestartSec=500msStartLimitInterval=0[Install]WantedBy=multi-user.target$ systemctl enable demo-api-redis@&#123;2,3&#125;$ systemctl start demo-api-redis@&#123;2,3&#125;$ systemctl restart demo-api-redis@1$ systemctl status demo-api-redis@&#123;1,2,3&#125;● demo-api-redis@1.service - HTTP Hello World Loaded: loaded (/etc/systemd/system/demo-api-redis@.service; enabled; vendor preset: disabled) Active: active (running) since Fri 2016-07-01 11:08:41 BST; 56min ago Main PID: 29884 (node) CGroup: /system.slice/system-demo\x2dapi\x2dredis.slice/demo-api-redis@1.service └─29884 /usr/bin/node index.jsJul 01 11:08:41 luke-arch systemd[1]: Stopped HTTP Hello World.Jul 01 11:08:41 luke-arch systemd[1]: Started HTTP Hello World.Jul 01 11:08:41 luke-arch node[29884]: (node:29884) DeprecationWarning: process.EventEmitter is deprecated. Use require('events') instead.Jul 01 11:08:41 luke-arch node[29884]: Listening on port 9001● demo-api-redis@2.service - HTTP Hello World Loaded: loaded (/etc/systemd/system/demo-api-redis@.service; enabled; vendor preset: disabled) Active: active (running) since Fri 2016-07-01 12:04:34 BST; 18s ago Main PID: 30747 (node) CGroup: /system.slice/system-demo\x2dapi\x2dredis.slice/demo-api-redis@2.service └─30747 /usr/bin/node index.jsJul 01 12:04:34 luke-arch systemd[1]: Started HTTP Hello World.Jul 01 12:04:34 luke-arch node[30747]: (node:30747) DeprecationWarning: process.EventEmitter is deprecated. Use require('events') instead.Jul 01 12:04:34 luke-arch node[30747]: Listening on port 9002● demo-api-redis@3.service - HTTP Hello World Loaded: loaded (/etc/systemd/system/demo-api-redis@.service; enabled; vendor preset: disabled) Active: active (running) since Fri 2016-07-01 12:04:34 BST; 18s ago Main PID: 30753 (node) CGroup: /system.slice/system-demo\x2dapi\x2dredis.slice/demo-api-redis@3.service └─30753 /usr/bin/node index.jsJul 01 12:04:34 luke-arch systemd[1]: Started HTTP Hello World.Jul 01 12:04:34 luke-arch node[30753]: (node:30753) DeprecationWarning: process.EventEmitter is deprecated. Use require('events') instead.Jul 01 12:04:34 luke-arch node[30753]: Listening on port 9003 We should now be able to curl each of these: 12$ curl localhost:900&#123;1,2,3&#125;"Hello, world 192.168.1.39! 52 hits.""Hello, world 192.168.1.39! 53 hits.""Hello, world 192.168.1.39! 54 hits." I’m assuming a 4-core machine, so I’m running three instances, leaving one core for Redis (which is probably not necessary). Adjust this accordingly for your environment and application. Now, on to the final part: load balancing. Load BalancingOne could use NGINX or HAProxy to balance the traffic across the instances of our service. However, since I’m claiming that it’s super simple to replace PM2 functionality, I wanted to go with something lighter. Balance is a tiny (few-hundred lines of C) TCP load balancer that’s fast and simple to use. For example: 123$ balance -f 9000 127.0.0.1:900&#123;1,2,3&#125; &amp;$ curl localhost:9000"Hello, world 192.168.1.39! 20 hits." The above one-liner launches balance, listening on port 9000 and balancing across ports 9001-9003. But we don’t want to run it in the foreground like this. Let’s write a unit file: 123456789101112131415161718192021222324252627$ cat /etc/systemd/system/balance.service[Unit]Description=Balance - Simple TCP Load BalancerAfter=syslog.target network.target nss-lookup.target[Service]ExecStart=/usr/bin/balance -f 9000 127.0.0.1:9001 127.0.0.1:9002 127.0.0.1:9003[Install]WantedBy=multi-user.target$ systemctl daemon-reload$ systemctl enable balance$ systemctl start balance$ systemctl status balance● balance.service - Balance - Simple TCP Load Balancer Loaded: loaded (/etc/systemd/system/balance.service; enabled; vendor preset: disabled) Active: active (running) since Fri 2016-07-01 13:56:46 BST; 3s ago Main PID: 32674 (balance) Tasks: 1 (limit: 512) Memory: 316.0K CPU: 10ms CGroup: /system.slice/balance.service └─32674 /usr/bin/balance -f 9000 127.0.0.1:9001 127.0.0.1:9002 127.0.0.1:9003Jul 01 13:56:46 luke-arch systemd[1]: Started Balance - Simple TCP Load Balancer.$ curl localhost:9000"Hello, world 192.168.1.39! 21 hits." ConclusionWe’ve successfully recreated the three main features of PM2 using basic Linux tools, in fact, mostly just systemd. But this is only a very basic implementation. There are a number of details I’ve overlooked for the sake of simplicity: SSL termination. Ports 9001-9003 are currently bound to the public IP, not the private (this is just laziness in my Node.js sample app). The balance unit file has hardcoded ports 9001-9003; it should be relatively easy to dynamically configure balance and send it a signal to reload config. I’d normally use containers so that the dependencies (e.g., Node.js version) is bundled inside the container and doesn’t need to be installed on the host. Linux init systems such as systemd are the ultimate process monitor, and systemd in particular is so much more than that. It can do all that PM2 and similar tools can do, and then some. The tooling is far superior, it’s more mature, and it has a much larger userbase of seasoned sysadmins. Learning to use systemd for running your Node.js applications (or any other applications for that matter) is much easier than you might think. Once you’ve spent a little time learning these concepts, I think you’ll agree that Linux is the best tool for the job. After all, you’ll need to configure the Linux init systemd to start PM2 on boot and restart it if it crashes. If you need the Linux init system to start your process monitor, why not just use it to run all your services? Further Reading systemd distros Good article on using systemctl Good article on using journalctl The creator of systemd talking about security features Videos from systemd conf 2015 systemd man pages – unit systemd man pages – service]]></content>
      <tags>
        <tag>sysadmin</tag>
        <tag>deployment</tag>
        <tag>nodejs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7中安装MongoDB]]></title>
    <url>%2F2018%2F04%2F16%2FCentOS7%E4%B8%AD%E5%AE%89%E8%A3%85MongoDB%2F</url>
    <content type="text"><![CDATA[本文概述了自己在CentOS7操作系统的服务器上安装配置MongoDB的一些基本步骤，供读者参考。 删除旧版本如果系统中已经装有旧版本，请重点关注以下步骤。如果没有旧版本可以直接跳过本章节。 Step 1: 配置文件备份一般当前的配置文件会存放在 /etc/mongod.conf 中。通过查阅该文件也可以定位数据文件和日志文件的存放位置。 Step 2: 数据文件备份备份，备份，备份！（重要的事情说三遍）。建议使用mongodumps -o some_dir命令来备份。由于导出的是bson文件，相比较mongoexport效率更高。 Step 3: 删除旧版本12yum remove mongodb-orgyum autoremove 安装这里通过官方安装源安装，虽然速度慢，但步骤非常简洁。 创建 /etc/yum.repos.d/mongodb-org-3.6.repo 文件，添加一下内容： 123456[mongodb-org-3.6]name=MongoDB Repositorybaseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/3.6/x86_64/gpgcheck=1enabled=1gpgkey=https://www.mongodb.org/static/pgp/server-3.6.asc 随后运行安装命令 1yum install -y mongodb-org 关闭SELinux之前在Azure的Ubuntu的服务器上好像没有遇到过这个问题。公司里的CentOS7镜像默认是 enforcing 模式。 简单带各位回顾一下今早踩过的一个坑： 同事之前帮忙部署了一台mongodb实例，数据文件是从之前一台已经弃用的服务器上scp拷贝过来的。我今天计划想把这台实例加固一下，首先就升级了系统然后reboot。没想到重启之后，mongodb的实例就没有自动启动起来。尝试使用 systemctl start mongod 就报错。追查到 /var/log/mongodb/mongod.log 中，就发现是访问磁盘路径时报了权限错误。这我就纳闷了，我只是重启了一下机器，怎么正常的启动脚本就失效了呢？ 尝试直接在root账户下运行 mongod，没问题 检查数据文件路径，文件所有者和访问模式都没毛病 卸载mongodb程序，删除所有配置，重新安装，还是不行 删除数据文件，使用root账户运行 mongod 初始化数据文件，然后再 chown -R mongod:mongod /data/db 改文件所有者，还是不行 很郁闷问题到底出在哪里了，也没有任何报错信息提示是 SELinux 造成。询问同事之前怎么安装的了，回答我说时间太久忘记了。。 嗯之后网上搜索询问抓狂的细节我也不多说了。直奔结果，最终还是在 StackOverflow 上的一篇未被采纳的回答里找到了答案原文地址。恍然大悟一定是同事之前部署的时候没有在 /etc/selinux/config 中持久化配置。虽然我也不理解SELinux到底是怎么回事，简单起见这里建议关闭。在配置中修改： 1SELINUX=disabled 修改完之后记得重启机器生效。重启后可以通过 getenforce 命令查看当前生效的模式。 修改数据存储位置mongodb的默认存储位置是 /var/lib/mongo。通常这个路径的挂载位置是系统盘，数据盘我通常会挂在至 /data 目录。在 /etc/mongod.conf 中修改数据存储的路径。修改 storage 配置： 1234storage: journal: enabled: true dbpath: /data/db 禁用THP 原文地址：https://docs.mongodb.com/manual/tutorial/transparent-huge-pages/ 创建启动项： /etc/init.d/disable-transparent-hugepages 12345678910111213141516171819202122232425262728293031323334353637383940#!/bin/bash### BEGIN INIT INFO# Provides: disable-transparent-hugepages# Required-Start: $local_fs# Required-Stop:# X-Start-Before: mongod mongodb-mms-automation-agent# Default-Start: 2 3 4 5# Default-Stop: 0 1 6# Short-Description: Disable Linux transparent huge pages# Description: Disable Linux transparent huge pages, to improve# database performance.### END INIT INFOcase $1 in start) if [ -d /sys/kernel/mm/transparent_hugepage ]; then thp_path=/sys/kernel/mm/transparent_hugepage elif [ -d /sys/kernel/mm/redhat_transparent_hugepage ]; then thp_path=/sys/kernel/mm/redhat_transparent_hugepage else return 0 fi echo 'never' &gt; $&#123;thp_path&#125;/enabled echo 'never' &gt; $&#123;thp_path&#125;/defrag re='^[0-1]+$' if [[ $(cat $&#123;thp_path&#125;/khugepaged/defrag) =~ $re ]] then # RHEL 7 echo 0 &gt; $&#123;thp_path&#125;/khugepaged/defrag else # RHEL 6 echo 'no' &gt; $&#123;thp_path&#125;/khugepaged/defrag fi unset re unset thp_path ;;esac 随后运行以下命令： 12chmod 755 /etc/init.d/disable-transparent-hugepageschkconfig --add disable-transparent-hugepages 设置数据库用户 原文地址：https://docs.mongodb.com/manual/tutorial/enable-authentication/ mongodb装好默认是不开启auth的（鉴权authentication与访问授权authorization）。在配置文件中启用auth之前，需要先在默认的 admin 库中创建一个 userAdminAnyDatabase 角色的用户。该角色可以在任一库中创建用户，但不能对库本身进行操作。 首先在后台启动实例： 1systemctl start mongod 随后使用mongo命令行登录，并用以下命令创建第一个用户： 12345678use admindb.createUser( &#123; user: "myUserAdmin", pwd: "abc123", roles: [ &#123; role: "userAdminAnyDatabase", db: "admin" &#125; ] &#125;) 随后退出客户端。至此已具备开启auth的条件。重启服务后使用如下命令重新登录： 1mongo -u "myUserAdmin" -p "abc123" --authenticationDatabase "admin" 然后新建其他用户： 123456789use testdb.createUser( &#123; user: "myTester", pwd: "xyz123", roles: [ &#123; role: "readWrite", db: "test" &#125;, &#123; role: "read", db: "reporting" &#125; ] &#125;) 注：mongodb的用户可以创建在任何一个库中，通过角色可以为其分配访问其他库的权限。但经实际测试，使用客户端登录时，登录的库必须是该用户所在的库，只能用use命令切换至其他库访问。这点比较奇怪，还待探明。 大功告成最后一步，当然是设置开机自动启动服务啦。 1systemctl enable mongod 未完待续过段时间会继续补充mongodb集群模式的安装和配置。敬请期待！]]></content>
      <tags>
        <tag>sysadmin</tag>
        <tag>database</tag>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IPTables HowTos]]></title>
    <url>%2F2018%2F04%2F11%2FIPTables-HowTos%2F</url>
    <content type="text"><![CDATA[This article describes basic usage of linux iptables. Sources CentOS HowTos DigitalOcean iptables List Rules12345678910111213141516171819202122232425262728293031323334353637383940414243444546sudo iptables --list -n --line-numbers# --list: or -L, list rules# -n: use port number instead of protocol name# --line-numbers: add ID numbers to the rules for further operations, e.g. deleting# A sample output (172.20.20.207, as of 20171221):Chain INPUT (policy DROP)num target prot opt source destination1 ACCEPT all -- 0.0.0.0/0 0.0.0.0/02 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:223 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:214 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:805 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:4436 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:30307 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:63798 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:80809 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:300010 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:300111 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:809012 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:809113 ACCEPT icmp -- 0.0.0.0/0 0.0.0.0/0 icmptype 814 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:567215 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:1567216 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:667717 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:668218 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:668019 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:567820 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:500121 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:668322 ACCEPT all -- 0.0.0.0/0 0.0.0.0/0 state RELATED,ESTABLISHED23 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:424224 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:500525 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:500626 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:500027 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:330728 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:330829 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:1567230 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:5672Chain FORWARD (policy DROP)num target prot opt source destinationChain OUTPUT (policy ACCEPT)num target prot opt source destination To show packet counts and aggregate size in the INPUT chain: 1sudo iptables -L INPUT -v Delete Rules12345678# delete a single rule in the INPUT chainsudo iptables -D INPUT 3# flush all rules in the INPUT chainsudo iptables -F INPUT# flush all chainssudo iptables -F Chains INPUT - All packets destined for the host computer. OUTPUT - All packets originating from the host computer. FORWARD - All packets neither destined for nor originating from the host computer, but passing through (routed by) the host computer. This chain is used if you are using your computer as a router. Default Policy DROP: if no ACCEPT rules are set, drop all packages ACCEPT: if no DROP rules are set, accept all packages CLI Walktrhough12345678iptables -P INPUT ACCEPTiptables -Fiptables -A INPUT -i lo -j ACCEPTiptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPTiptables -A INPUT -p tcp --dport 22 -j ACCEPTiptables -P INPUT DROPiptables -P FORWARD DROPiptables -P OUTPUT ACCEPT Explanation: iptables -P INPUT ACCEPT If connecting remotely we must first temporarily set the default policy on the INPUT chain to ACCEPT otherwise once we flush the current rules we will be locked out of our server. iptables -F We used the -F switch to flush all existing rules so we start with a clean state from which to add new rules. iptables -A INPUT -i lo -j ACCEPT Now it’s time to start adding some rules. We use the -A switch to append (or add) a rule to a specific chain, the INPUT chain in this instance. Then we use the -i switch (for interface) to specify packets matching or destined for the lo (localhost, 127.0.0.1) interface and finally -j (jump) to the target action for packets matching the rule - in this case ACCEPT. So this rule will allow all incoming packets destined for the localhost interface to be accepted. This is generally required as many software applications expect to be able to communicate with the localhost adaptor. iptables -A INPUT -m state –state ESTABLISHED,RELATED -j ACCEPT This is the rule that does most of the work, and again we are adding (-A) it to the INPUT chain. Here we’re using the -m switch to load a module (state). The state module is able to examine the state of a packet and determine if it is NEW, ESTABLISHED or RELATED. NEW refers to incoming packets that are new incoming connections that weren’t initiated by the host system. ESTABLISHED and RELATED refers to incoming packets that are part of an already established connection or related to and already established connection. iptables -A INPUT -p tcp –dport 22 -j ACCEPT Here we add a rule allowing SSH connections over tcp port 22. This is to prevent accidental lockouts when working on remote systems over an SSH connection. We will explain this rule in more detail later. iptables -P INPUT DROP The -P switch sets the default policy on the specified chain. So now we can set the default policy on the INPUT chain to DROP. This means that if an incoming packet does not match one of the following rules it will be dropped. If we were connecting remotely via SSH and had not added the rule above, we would have just locked ourself out of the system at this point. iptables -P FORWARD DROP Similarly, here we’ve set the default policy on the FORWARD chain to DROP as we’re not using our computer as a router so there should not be any packets passing through our computer. iptables -P OUTPUT ACCEPT and finally, we’ve set the default policy on the OUTPUT chain to ACCEPT as we want to allow all outgoing traffic (as we trust our users). iptables -L -v Finally, we can list (-L) the rules we’ve just added to check they’ve been loaded correctly. Finally: 1sudo /sbin/service iptables save Executable scriptOpen a text editor: 12345678910111213141516171819202122232425262728293031323334#!/bin/bash## iptables example configuration script## Flush all current rules from iptables#iptables -F## Allow SSH connections on tcp port 22# This is essential when working on remote servers via SSH to prevent locking yourself out of the system#iptables -A INPUT -p tcp --dport 22 -j ACCEPT## Set default policies for INPUT, FORWARD and OUTPUT chains#iptables -P INPUT DROPiptables -P FORWARD DROPiptables -P OUTPUT ACCEPT## Set access for localhost#iptables -A INPUT -i lo -j ACCEPT## Accept packets belonging to established and related connections#iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT## Save settings#/sbin/service iptables save## List rules#iptables -L -v Save the script then make it executable: 1chmod +x myfirewall]]></content>
      <tags>
        <tag>sysadmin</tag>
        <tag>iptables</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JKOM CentOS VM Setup]]></title>
    <url>%2F2018%2F04%2F11%2FJKOM-CentOS-VM-Setup%2F</url>
    <content type="text"><![CDATA[This article describes the steps of initiating a CentOS VM normally used with JKOM’s private network. Here are the technical requirements: create user jk with root privilage disable root login from remote disable firewall as it’s in local network dev-tools such as git python 3.6 node 8.9.3 Basics1ssh root@server_ip_address Fix locale warning123456sudo vim /etc/environment# add these lines...LANG=en_US.utf-8LC_ALL=en_US.utf-8 re-login Package update1yum update Disable firewall12systemctl stop firewalld.servicesystemctl disable firewalld.service add user:jk with sudo permission123adduser jkpasswd jkusermod -aG wheel jk disable root login1234567sudo yum install vimsudo vim /etc/ssh/sshd_configPermitRootLogin noPubkeyAuthentication yessudo service sshd restart re-login with ssh jk@server_ip_address PubKey login1234ssh-keygen -t rsacdvim .ssh/authorized_keyschmod 600 .ssh/authorized_keys Install oh-my-zsh123sudo yum install zshsudo yum install gitsh -c "$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)" Code EnvPython312345678910111213141516sudo yum -y updatesudo yum -y install yum-utilssudo yum -y groupinstall developmentsudo yum -y install https://centos7.iuscommunity.org/ius-release.rpmsudo yum -y install python36usudo yum -y install python36u-pipsudo yum -y install python36u-develcdmkdir .pipvim .pip/pip.conf# add the following config[global]index-url = https://mirrors.ustc.edu.cn/pypi/web/simpleformat = columns Nodejs123456789cdcurl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.8/install.sh | bash# re-loginnvm install 8.9.3npm install -g cnpm --registry=https://registry.npm.taobao.orgcnpm install -g pm2sudo env PATH=$PATH:/home/jk/.nvm/versions/node/v8.9.3/bin /home/jk/.nvm/versions/node/v8.9.3/lib/node_modules/pm2/bin/pm2 startup systemd -u jk --hp /home/jk ODBC Driverreference 123456sudo sucurl https://packages.microsoft.com/config/rhel/6/prod.repo &gt; /etc/yum.repos.d/mssql-release.repoexitsudo yum remove unixODBC-utf16 unixODBC-utf16-develsudo ACCEPT_EULA=Y yum install msodbcsqlsudo yum install unixODBC-devel # required by pyodbc ZeroMQ12sudo yum -y install zeromqsudo yum -y install zeromq-devel # required by zerorpc]]></content>
      <tags>
        <tag>centos</tag>
        <tag>sysadmin</tag>
        <tag>jkom</tag>
      </tags>
  </entry>
</search>
